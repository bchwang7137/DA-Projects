---
fontsize: 12pt
geometry: margin=1in
linkcolor: black
urlcolor: black
output: pdf_document
bibliography: references.bib 
nocite: '@*'
header-includes:
- \usepackage{setspace}
- \onehalfspacing
---

```{r setup4, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, highlight=FALSE, message=FALSE)
```

```{r, echo = FALSE, warning = FALSE, message = FALSE, include = FALSE}
# Library statements
library(knitr)
library(tidyverse)
library(tidymodels)
library(modelr)
library(randomForest)
library(Metrics)
library(GGally)
library(stats)
library(car)
library(yardstick)

# Initial Data Prep (covered in Deliverable 2)
mydata <- read_csv("~/RStudio/STAT 4220 - Biz Analytics/Data/conversion.csv")
mydata$fb_campaign_id <- NULL
mydata$interest <- NULL
names(mydata) <- tolower(names(mydata))
names(mydata)[names(mydata) == "gender"] <- "male"
names(mydata)[names(mydata) == "xyz_campaign_id"] <- "campaign"
names(mydata)[names(mydata) == "total_conversion"] <- "total_conv"
names(mydata)[names(mydata) == "approved_conversion"] <- "app_conv"
mydata$male[mydata$male == 'M'] <- 1
mydata$male[mydata$male == 'F'] <- 0
mydata$male <- as.integer(mydata$male)
mydata$age[mydata$age == '30-34'] <- 32
mydata$age[mydata$age == '35-39'] <- 37
mydata$age[mydata$age == '40-44'] <- 42
mydata$age[mydata$age == '45-49'] <- 47
mydata$age <- as.integer(mydata$age)
mydata$campaign[mydata$campaign == 916] <- "campaign_1"
mydata$campaign[mydata$campaign == 936] <- "campaign_2"
mydata$campaign[mydata$campaign == 1178] <- "campaign_3"
mydata$campaign <- as.factor(mydata$campaign)

# Additional Data Prep (Predictive Analytics)
# Create dummy variables for different levels of Campaign
mydata <- mydata %>%
  mutate(is_c1 = ifelse(campaign=="campaign_1",1,0),
         is_c2 = ifelse(campaign=="campaign_2",1,0))

# Set seed for data splitting
set.seed(4220)
# All-Campaign training/validation/testing sets
fb.div <- mydata %>%
  initial_split(prop = 0.6, strata = campaign)
fb.div1 <- fb.div %>%
  testing() %>%
  initial_split(prop = 0.5, strata = campaign)
fb.train <- training(fb.div)
fb.val <- training(fb.div1)
fb.test <- testing(fb.div1)

# Random Forest Analysis - Initial Models
rf.app <- randomForest(app_conv ~ age + male + impressions + 
                         clicks + spent + is_c1 + is_c2, 
                       data = fb.train, mtry = 2, importance = TRUE)
rf.tot <- randomForest(total_conv ~ age + male + impressions + 
                         clicks + spent + is_c1 + is_c2,
                       data = fb.train, mtry = 2, importance = TRUE)
# Random Forest Analysis - Pruned Models
rf.app.1 <- randomForest(app_conv ~ age + impressions + clicks + spent, 
                           data = fb.train, mtry = 2, importance = TRUE)
rf.tot.1 <- randomForest(total_conv ~ age + impressions + clicks + spent, 
                           data = fb.train, mtry = 2, importance = TRUE)

# Assessment - Training Data
mods.tr <- c("Initial - Approved Conversion",
             "Reduced - Approved Conversion",
             "Initial - Total Conversion",
             "Reduced - Total Conversion")
rmse.tr <- c(sqrt(rf.app$mse[length(rf.app$mse)]),
             sqrt(rf.app.1$mse[length(rf.app.1$mse)]),
             sqrt(rf.tot$mse[length(rf.tot$mse)]),
             sqrt(rf.tot.1$mse[length(rf.tot.1$mse)]))
sum.tr <- data.frame(mods.tr, rmse.tr)

# Assessment - Validation Data
pred.init.app <- predict(rf.app, fb.val)
pred.red.app <- predict(rf.app.1, fb.val)
pred.init.tot <- predict(rf.tot, fb.val)
pred.red.tot <- predict(rf.tot.1, fb.val)
mods.v <- c("Initial - Approved Conversion",
            "Reduced - Approved Conversion",
            "Initial - Total Conversion",
            "Reduced - Total Conversion")
rmse.v <- c(rmse(fb.val$app_conv, pred.init.app),
            rmse(fb.val$app_conv, pred.red.app),
            rmse(fb.val$total_conv, pred.init.tot),
            rmse(fb.val$total_conv, pred.red.tot))
sum.v <- data.frame(mods.v, rmse.v)

# Assessment - Testing Data
pred.test.app <- predict(rf.app, fb.test)
pred.test.tot <- predict(rf.tot, fb.test)
rmse(fb.test$app_conv, pred.test.app)
rmse(fb.test$total_conv, pred.test.tot)
mods.t <- c("Initial - Approved Conversion",
            "Initial - Total Conversion")
rmse.t <- c(rmse(fb.test$app_conv, pred.test.app),
            rmse(fb.test$total_conv, pred.test.tot))
sum.t <- data.frame(mods.t, rmse.t)

# Variable Importance
varnam <- c("Impressions", "Spent", "Clicks", "Age", 
            "Campaign 2", "Campaign 1", "Male")
app.imp <- c(21.667, 15.536, 15.235, 13.526, 9.747, -0.153, 4.458)
tot.imp <- c(23.868, 17.291, 15.348, 18.842, 12.147, 5.464, 2.760)
sum.imp <- data.frame(varnam, app.imp, tot.imp)

# Final Models
LinReg.mod1 = lm(total_conv ~ age + impressions + clicks + spent + is_c1 + is_c2, 
                 data = fb.train)
LinReg.mod.a3 <- lm(app_conv ~ impressions + spent + is_c1 + is_c2, 
                    data = fb.train)

## SUMMARY TABLES LINREG
mods.lr <- c("Initial - Approved Conversion",
             "Final - Approved Conversion",
             "Initial - Total Conversion",
             "Final - Total Conversion")
mods.lr1 <- c("Initial - Approved Conversion",
             "Initial - Total Conversion")
rmse.lr.tr <- c(3.63, 3.87, 2.14, 2.21)
rmse.lr.v <- c(4.60, 5.39, 2.14, 2.21)
rmse.lr.te <- c(4.32, 2.86)

sum.lr.tr <- data.frame(mods.lr, rmse.lr.tr)
sum.lr.v <- data.frame(mods.lr, rmse.lr.v)
sum.lr.te <- data.frame(mods.lr1, rmse.lr.te)

Final_Total = coef(summary(LinReg.mod1))

row.names(Final_Total) <- c("(Intercept)", "Age", "Impressions", "Clicks", 
                            "Spent", "Campaign 1", "Campaign 2")

Final_TotalR = data.frame("R2" = 0.7556, "Adj. R2" = 0.7535, "P-Value" = "< 2.2e-16")

Final_Approved = coef(summary(LinReg.mod.a3))

row.names(Final_Approved) <- c("(Intercept)", "Impressions", "Spent", 
                               "Campaign 1", "Campaign 2")

Final_ApprovedR = data.frame("R2" = 0.6098, "Adj. R2" = 0.6075, "P-Value" = "< 2.2e-16")
```

# Predictive analytics

The specific goal of our predictive analytics is to observe how a variety of factors contribute to the performance of online marketing campaigns. In particular, we are focused on determining which factors have the greatest impact on campaign success. It is worth noting that firms that are interested in boosting their brand awareness may find total conversion to be the most suitable measurement of ad performance. On the other hand, firms that are more interested in boosting sales may find approved conversion to be the more appropriate metric. Therefore, we intend to explore the impact of the various features in our dataset on two separate response metrics — total conversion and approved conversion. We will build out linear regression and random forest models for the two distinct response metrics to achieve these goals.

## Process

The predictive analytics process began with the splitting of our full dataset into smaller representative subsets for the purpose of training and evaluating the predictive models that we developed. After carrying out this step, we considered our methodological options and decided to implement multiple linear regression and random forest models in our analysis. We decided to proceed with these methodologies because they allow for the use of all types of variables to predict the outcome of the given quantitative response variables.
\newline

For both methods, an initial set of two separate models — one for each response variable — containing all the primary variables was built. The initial models included the variables of target audience’s age and gender, a firm’s per-advertisement spending, the specific marketing campaign associated with the ad, and the number of clicks and impressions generated over the course of an advertisement’s deployment. One model was built to predict approved conversion and another was built to predict total conversion. 
\newline

Next, variables that may not provide useful information for accurate prediction were removed to create different models that were later compared to the originals. These models were evaluated through various assessment methods that measure model prediction error. Finally, the models with the lowest prediction errors were chosen as the final models in our analysis.

## Assessments

We first utilized the linear regression method in our analysis. Figure 1 and Figure 2 below depict moderate to strong linear relationships between the different key performance indicators and our two response variables — total conversion and approved conversion, respectively. Additionally, we did not encounter any grievous violations of the relevant model building assumptions, so we decided that it would be appropriate to proceed with our analysis.

```{r, echo=FALSE, fig.cap="Correlation Plot of Quantitative Predictors and Total Conversion"}
#Total Conversion
fb.train %>%
select(impressions, clicks, spent, total_conv) %>%
ggpairs(title = "Scatterplot of Quantitative Variables - Total Conversion",
columnLabels = c("Impressions", "Clicks", "Spent", "Total Conversion")) 
```
\newpage

```{r, echo=FALSE, fig.cap="Correlation Plot of Quantitative Predictors and Approved Conversion"}
#Approved Conversion
fb.train %>%
select(impressions, clicks, spent, app_conv) %>%
ggpairs(title = "Scatterplot of Quantitative Variables - Approved Conversion",
columnLabels = c("Impressions", "Clicks", "Spent", "Approved Conversion"))
```

Upon conducting a regression analysis on our initial model, we saw that only a handful of predictors were significant. We hence iteratively removed the least significant variables from the model and conducted overall significant tests to approach our final models for assessment. We were left with a pair of models for both of our response variables.
\newline

The model that had the highest proportion of variance explained in predicting total conversion, also known as R-Squared, had high degrees of multicollinearity. We decided to remove the variable that most contributed to this undesirable intercorrelation within the model. This resulted in a final model with more manageable levels of multicollinearity, though this came at the cost of a slightly lower R-Squared value.
\newline

Similarly, the model predicting approved conversion that had the highest R-squared value also had high multicollinearity. We once again compared this model to one without the variable that contributed to the high multicollinearity to result in a model with little to no multicollinearity but a far lower R-squared value. 
\newline

The full and reduced models for each response variable were then assessed based on their respective prediction error, measured by the root mean squared error values, or RMSE. A lower RMSE is indicative of a model with better fit to the data. While our goal does not necessarily lie in predicting some value, these assessment measures are important because they give us valuable information regarding the soundness of our models. Since we are interested in making inferences about the relationship between our two response variables and the selected predictors, we want to be using the best possible models as a basis for drawing these conclusions.
\newline

```{r, echo=FALSE}
sum.lr.v %>%
  kable(col.names = c("Model Name", "RMSE"),
        caption = "Linear Regression Model Assessment - Validation Set")
```

The table above summarizes the linear regression model assessment results based on the validation data. The initial models for total conversion and approved conversion result in lower prediction errors and thus seem to better fit our data. We hence continue with these models as our final models of choice.
\newline

```{r, echo=FALSE}
sum.lr.te %>%
  kable(col.names = c("Model Name", "RMSE"),
        caption = "Linear Regression Model Assessment - Testing Set")
```

The table above summarizes the linear regression model assessment results based on the testing data.
\newline

Next, our team conducted a random forest analysis. We began by building an initial pair of models containing all of our primary predictor variables. Next, we built a set of simpler models by sequentially removing variables with very low variable importance. The goal of this procedure is to discover an alternative model that demonstrates comparable performance in assessments while also being simpler and easier to interpret. In our case, this involved removing the predictor variables associated with the target audience’s gender, as well as the variable associated with the specific marketing campaign each ad belonged to.
\newline

While these simpler models may be slightly easier to interpret, our team was also careful about their performance relative to the full, initial models. We found that any further variable removals resulted in drastic reductions in various model assessment metrics. Additionally, all of the remaining predictors indicated high variable importance during our exploratory assessments. Therefore, we retained these remaining variables in our final models and made no further changes. Each of these models were once again assessed based on their respective prediction error by looking at RMSE values.
\newline

```{r, echo=FALSE}
sum.v %>%
  kable(col.names = c("Model Name", "RMSE"),
        caption = "Random Forest Model Assessment - Validation Set")
```

The table above summarizes the random forest model assessment results based on the validation data. The initial approved conversion and initial total conversion models demonstrated lower prediction errors. As such, our group decided to select these two models as our final random forest models of choice. 
\newline

```{r, echo=FALSE}
sum.t %>%
  kable(col.names = c("Model Name", "RMSE"),
        caption = "Random Forest Model Assessment - Testing Set")
```

The table above summarizes the final random forest model assessment results based on the testing data. Interestingly enough, the two final models demonstrate lower prediction error here relative to the earlier assessment results.

## Results 
As seen in the tables below, our final linear regression model indicates that the audience’s age, and the number of clicks and impressions generated over the course of an advertisement’s deployment, a firm’s per-advertisement spending, and the specific marketing campaign associated with the ad are important predictors for total conversion. The number of impressions generated over the course of an advertisement’s deployment, a firm’s per-advertisement spending, and the specific marketing campaign associated are important variables in predicting approved conversion. While a few of these variables turned out to be individually insignificant, we found that the models that excluded these relevant variables were not as adequate. 

```{r, echo=FALSE}
knitr::kable(list(Final_Total, Final_TotalR), 
             caption = 'Total Conversion Results', 
             booktabs = TRUE, valign = 't')
```

```{r, echo=FALSE}
knitr::kable(list(Final_Approved, Final_ApprovedR),
             caption = 'Approved Conversion Results',
             booktabs = TRUE, valign = 't')
```
\newpage

Our final model for total conversion results in a R-squared value of 0.7556, meaning that about 75.56% of the variation in total conversion is attributed to our model. Similarly, the final model for approved conversion results in a R-squared value of 0.6098, meaning that about 60.98% of the variation in approved conversion is explained by our model.
\newline

The results of our random forest model analysis are summarized in the table below. The leftmost column contains our final set of predictor variables, listed in order of decreasing importance. The values in the middle and rightmost columns are measures of each variable’s relative importance in each of our two random forest models. Higher values indicate greater variable importance, as these values represent a percent increase in prediction error that would result from the removal of each respective variable.
\newline

```{r, echo=FALSE}
sum.imp %>%
  kable(col.names = c("Variables", 
                      "Importance - Approved Conversion", 
                      "Importance - Total Conversion"),
        caption = "Random Forest Variable Importance - Higher Values for Higher Importance")
```

We find that the number of clicks and impressions generated over the course of an advertisement’s deployment, and a firm’s per-advertisement spending all appear to be important variables in both the approved conversion and total conversion models, as one might readily intuit. The less intuitive result lies within the relative importance of the demographic variables, as well as the campaign variables. The age of an advertisement’s target audience appears to be a relatively important factor in generating greater conversion, whereas target audience gender does not. Furthermore, it seems as though information about an advertisement belonging to the first marketing campaign is far less important than information about an advertisement belonging to the second marketing campaign.

## Insight summary

Based on the assessments we ran, we have information regarding the variables that affect marketing campaign success the most.
\newline

The number of times an ad was shown to the particular audience, i.e. the impressions generated over the course of an advertisement’s deployment is the most significant predictor of both total conversion and approved conversion as indicated by linear regression. Impressions also consistently demonstrated the highest level of variable importance across the two final random forest models. This suggests that a marketing campaign’s success as measured by total conversion and approved conversion largely hinges on the number of times the ads appear on user screens. This is somewhat intuitive, since ads that are shown more frequently have greater visibility and are therefore likely to induce more users to inquire about and ultimately purchase a product.
\newline

Per-advertisement spending is the second most important predictor of both total and approved conversion as concluded by both of the methodologies we employed. It is interesting to note, however, that an increase in the amount of money paid to deliver an advertisement actually decreases both total and approved conversion as per linear regression. Therefore, minimizing overall advertising costs, or at least making sure these funds are being used efficiently, seems to be beneficial for the success of a marketing campaign. 
\newline

We found the number of times a user clicked on a particular ad to be a significant variable in our total conversion linear regression models. It was also a variable of relatively high importance in both of our random forest models. We were surprised to see that it was not individually significant in predicting approved conversion in our linear regression models, especially when considering our firm’s utilization of a CPC pricing model. We believe that this may be due to the fact that the advertisements with the most conversions also tended to generate a large number of impressions and a relatively lower number of clicks. 
\newline

The age associated with the audience of a particular advertisement is a significant variable in our total conversion linear regression model. We find a negative relationship between age and total conversion, which suggests that younger audiences tend to inquire about our products more often. It is also a variable of importance in both of our random forest models. On the other hand, it is not a significant predictor of approved conversion in our linear regression model.
\newline

Our findings regarding the predictor variables associated with the specific marketing campaigns each ad belonged to were a mixed bag. Information regarding an advertisement’s association with Campaign 1 turned out to be insignificant, whereas the same for Campaign 2 turned out to be highly significant. We find it likely that this was caused by the disparity in scale between the three marketing campaigns. As previously discussed, Campaign 1 only contained 54 advertisements, whereas Campaign 2 and Campaign 3 contained 464 and 625 advertisements respectively. It seems clear enough from the assessment results that this variable provides our models with valuable information. However, the firm’s marketing department may be better equipped to delve into this result given our lack of information regarding the specific particulars of each campaign.
\newline

Finally, we found that the target audience’s gender was of relatively low importance for approved conversion, and of little to no importance for total conversion in our random forest models. It was also completely insignificant in both of our linear regression models.